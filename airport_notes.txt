Airport 

5/2015
Fixed data for DOC vs COD regression - I was using some preliminary data, fixed to only final data
	for 090814, there's only MeanConc (no FinalConc). Use this?
	for 03182014, no second tab on xlsx file, so skipped
	for 20141210/20141210b, which to use? replicates?
	for Lenaker012214, no second tab on xlsx file, so skipped
	for lenaker_041214, only MeanConc (no FinalConc). Use this?
	for 12232013, no second tab on xlsx file, so skipped
	for lenaker)121113, no second tab, so skipped
Missing DOC for CG S109, S112, S116; US S104, S105, S105G, S108, S108G, S112, S112G, S115, S116, S116A, S116B, S116C, W101, W104; 
LK S104, S104G, S105, S105G, S108, S108G, S112, S112G, S114, S115, S115A, S115B, S115C, S116, S116A, S116B, W101, W104; 
OUT S104, S104G, S105, S105G, S106, S108, S108G, S112, S112G, S114, S114A, S114B, S114C, S114D, S114E, S114F, S114G, S114H, S114J, S114K, S115, S115A, S115BD, S115E, S115FG, S115HJ, S115KL, S115M, S115NO, S115PQ, S115RS, S115T, S115UV, S116, S116A, S116B, S116C, W101, W104; 
OAK S104, S105, S106, S107, S108, S112, S115, S116, W101, W104

Added more residuals to dataset for regression. Re-running - double-check all the data omitted. Then run summary for best model. 
Send new results with included data/Sags and resids. 
Check on HG9 for deicer runs


1/2015
Pulled in DOC using HydroOpt
Used getExpResid function to look at residuals of regressions for spectra ranges
Fixed sign issues w/ regression equations on plots and summary
Added sample name to individual sample absorbence plots

Current state:
Using script absorbenceWorkflow.R
Script pulls in and formats absorbence data, removes duplicates when present, replaces negative values with minimum value above zero. 
Creates absorbence plots (absorbence vs frequency) for each sample as well as one of means. Calculates a couple residuals as well as reads 
in a file of spectral slopes. Then uses GSqwsr to find regression on COD for all possible variables.
Optical can be measured with a real-time field instrument (Steve is looking into manufacturers/instruments), and looks promising to be used 
for prediction of COD. DOC could be used, but doesn't look like as good of a predictor, problems with influence from natural sources of COD 
at low levels. Will also look into using the absorbence to predict acetate and glycol, but probably COD regression will be better. Tried 
adding water temperature, but it removed a lot of samples. Maybe from internal NWIS rather than web? Also didn't show up much as important.

* look at suspended solids to explain higher COD than predicted by DOC
* try adding A254 to COD vs DOC regression to see if helps (proxy for organic environmental carbon)
* switch away from GSqwsr stepwise regression to a process that tries all possible combos (up to a specified number of variables)
* w/in GSqwsr, seems like it would be useful to add a max number of variables, or set a min % change in AIC/BIC to continue
* take a look at my fixes and additions to graphs and outputs - should any be merged back into GSqwsr?
* refine COD vs DOC graph and add regression to it
* Future - may look at using categorical variable(s) in regression to represent site location, season, snowfall, etc
* Future - incorporate DOC to help tease out absorbence due to factors other than deicer
* Future - Pete will run absorbence on deicer samples we have so we can see exactly where they come out
* Future - more samples will be taken in between storms and tested for absorbence
* Future - data analysis and manuscript prep for this work. We (Steve, Pete and I) can begin the manuscript any time
* Future - work with Steve on his original dye study manuscript


12/2014
Current regression for all GMIA (OUT,CG,LK,OAK) sites with absorbence looks promising
Removed absorbence greater than 700 because absorbence plots of individual samples show no activity
Removed narrow spectral slopes, especially in the lower spectra, because individual samples absorbence plots don't show patterns there
Individual sample absorbence plots show peaks in the ~500 and ~600 areas
Added R2 to graphs and summary
Added shape to plot points on plotSteps graph to signify site (OUT,CG,LK,OAK)

* Fix equations written to plots and summary to include correct sign (+ or -). Value?
* Add sample name to individual sample absorbence plots
* Look at function in HydroOpt package to pull in DOC
* Send Sam changes I made to his finalAbs function 
* Send Steve note about error in getSag.R in HydroOpt - line 11 dfAbs should be dataAbs
* Put together graph of COD vs DOC and a regression to help Pete compute dilutions needed for running the deicers
* Seeing the strength of the seasonal term, try adding in water temperature (available for OUT, CG and LK). Use dataRetrieval to get the unit values, then use TSStormStats from Hydrotools to get mean water temp for the sampling periods using the beginning and ending dates and times of the samples
* Try using getExpResid function to focuses on a specified range of absorbance data, builds a regression with data on the left and right of that range, then computes the residual in the middle at a specified location. For example, consider page 8 of the graphs. The range from about 605 to 660 has a peak that we would focus on. We would build a regression based on data surrounding it, so from wavelengths 560-610 combined with 670 to 700. Then compute residuals from that regression at the wavelength where the peak is (~630 for page 8). The function does all of this and spits out another column of data.
* Write up notes on decisions, process, comments so script will be ready to go in May with this winter's data
* Future - may look at using categorical variable(s) in regression to represent site location, season, snowfall, etc
* Future - incorporate DOC to help tease out absorbence due to factors other than deicer
* Future - Pete will run absorbence on deicer samples we have so we can see exactly where they come out
* Future - more samples will be taken in between storms and tested for absorbence
* Future - data analysis and manuscript prep for this work. We (Steve, Pete and I) can begin the manuscript any time
* Future - work with Steve on his original dye study manuscript

6/2014
all merged and run. doesn't look all that promising. Steve wants to check next on possible relationship of optical/absorbence data to predicting COD


5/15/14
Now have hourly data merged with storm events. ice affected corrected. all data saved as workspace gmia_merged_data_hourly.RData.

Next:
set up to run for COD, BOD and EG+PG
run all data together, then split out residuals into different groups (different year breakpoints for pre/post)
right now using ice-affected corrected, which seems to be working fine. could switch to omitted
for EP+PG - need to check on how censored is working if one value is censored and one not. maybe add after running importQW?
for EG+PG from Steve:
 It would make sense to compute loads for both first. Use a general rule to follow when the values are censored (need to choose and estimate rather than assigning a censored load). Then add the loads
I have an idea for estimating....Develop a regression between COD and EG and between COD and PG. When values of PG or EG are censored, use COD to estimate them.




1/14/2014 status:
Have run many different versions of regression for storms at Outfall site joined to daily loads:
* all samples w/ load data for chosen (BOD, COD, EG, PG, EGPG), all with ice affected omitted, all using mmprcp from deicing data
* all precip (no 'melt' in description), all precip w/ ice affected omitted
* all snowmelt, all snowmelt w/ ice affected omitted
* all w/o Qmax, all precip w/o Qmax, all snowmelt w/o Qmax

These are all w/ daily joined by event start and end dt, match nearest w/in 36 hours, use all of those rows to find mean, max and min temp, prcp sum, 
dwpt mean and snowdp sum
These are all run w/ total glycol application info, not split out per site

Next/further work:
Finish comparison of hourly/daily - hard to tell because of units issues
Run regressions with hourly data, similar to those done w/ Daily
Need to find out when the breakpoint is between no management system and added containment, then split into two periods
Need to run other sites - Cargo and St. Lukes
Need to re-run all with split out glycol application info
Try different ways to join data:
* daily - not use whole day? maybe part of day based on hours? but don't know when snow happened necessarily? 
* hourly - anything other than just straight event begin and end? 
* try difference in snow depth and possible conversion to snow water equivalent
* event start/end vs application start/end, precip start/end; maybe use rain vs snow description, adapt rainmaker function to look for rain/snow
* definition of deicing event - temp, precip type, airport info, etc
Document data used - QWDATA, airport figures, NCDC weather, ADAPs discharge, etc
Compare residuals for regression for "before" and "after" periods and see if they sort into a couple groups. can test significance of difference between 
these groups using Wilcox or T-test
Maybe look into local climatological data? 

End goal: to try to predict propylene glycol load based on forcing factors, using a regression (probably step-wise). Determine if there is/has been a 
significant change in loading due to management practices.possible forcing factors: application amount/dilution factor, weather, precip type and amount, 
air temperature during de-icing event, (timing of de-icing events and number of planes, no data this necessarily, may need to infer) respose variables: 
COD and BOD (surrogates for combo of all de-icers), all de-icers (pavement de-icers, propylene glycol, ethylene glycol), but some of these are more 
accurate than others.

Background: monitoring began in 1996. One station above airport, not necessary to use for this study. Numbers are so low (background levels) w/o de-icer 
that we don't need to subtract out. Two stations at airport: Outfall 7, big site that drains most of the airport de-icing runoff; cargo site drains just 
a concentrated loading area. One station downstream from the airport: St. Luke's, results of a tracer study are used to calculate lag to this site for 
de-icing events. Approx 6 events per year. Defining an 'event' will be part of the difficulty - airport info, air temp, precip, etc are options. Used to 
use a mix of propylene glycol and ethylene glycol, but switched to all propylene glycol. don't have data for degradates, will ignore that for this study. 
For management practices, they have a bladder system that is supposed to capture runoff from the stream and suck it up. 


Data: 
//projects/nonpoint/gmia/R/ for preliminary weather data and R scripts for dealing with it
//projects/nonpoint/gmia/WQ2013/ for data pulled from NWIS QWData and calculated loads
http://w1.weather.gov/data/obhistory/KMKE.html
http://www.crh.noaa.gov/data/obhistory/KMKE.html

COD pcode 00335
BOD pcode 00310
ethylene glycol pcode 91075
propylene glycol pcode 91080

sites and nwisweb data available:
040871473 - infall
daily temp and discharge 1996-2013
peak streamflow 1998-2012
instantaneous data archive 1996-2007
qw COD,BOD,ethylene glycol and propylene glycol 1996-2013
040871475 - outfall #7
**daily temp 1996-2013, daily discharge 2005-2013
**peak streamflow 2006-2012
**instantaneous data archive 2005-2007
qw COD, BOD, ethylene glycol, propylene glycol and discharge 1996-2013
040871476 - outfall #1 (Cargo)
daily temp and discharge 1996-2013
peak streamflow 1998-2008
instantaneous data archive 1996-2007
qw COD,BOD,ethylene glycol and propylene glycol 1996-2013
040871488 - st luke's
daily temp and discharge 1996-2013
peak streamflow 1998-2012
instantaneous data archive 1996-2007
qw COD,BOD,ethylene glycol and propylene glycol 1996-2013

Data Inventory:

//deicer collection/deicer collection through 2004 winter.xls
contains dates (day-level) and 'pure glycol', units unknown for 12/1/1999 through 4/15/2004, w/ breaks each year april-nov
//deicer usage/COD volumes and loads/
files for 2008, 2002, 2003, 2004 - COD and glycol/deicer
files for 2009, 2011, 2012, 2002-2005, 2010
//deicer usage/
cargo and outfall deicer usage dec 99 and jan 00
cargo and outfall decier usage nov 2001-april 2002
cargo and outfall deicer usage nov 2002-april 2003
deicer usage nov 2003-aprile 2004
deicer usage nov 2004-april 2005
**2006 and 2007 are missing**
deicer usage nov 2007-april 2008
deicer usage 1/24/03 - 4/15/07
deicer usage nov 2008-april 2009
deicer usage nov 2009-april 2010
deicer usage nov 2010-april 2011
//event notes/
contains info about events for WY 2001-2013, discharge, volume, etc
//Loads/
mostly old (?) load data
//WY 2013 QW data/
gmia.qw.5.1996-2012.with.loadings.xlsx - I believe this is the file that contains everything, although Troy may not be finished with it
//R/
st lukes sample times
outfall7_air_temp_2006-2009.RDB 15-minute air temp data for outfall #7 pulled from NWIS
milw.weather.1990-2011.xls - daily weather data (precip, snowfall, snow depth, water equivalent of snow on ground, binary info on precip type
gmia start end storm dates
gmia_rain_2000-2012.txt hourly precip data

Data from NCDC:
Precip
15-minute - NA
Hourly Precip - acquired
**Hourly Global - acquired** gives hourly wind, sky condition, visibility, temp, precip, dewpoint, atm pressure, snow depth, snow accumulation, 
weather obs, cloud data, etc  - seems to match local data hourly obs found by steve
GHCN Daily CoCoRaHS - NA
GHCN Daily GHCN - acquired
GHCN Daily WMO - NA
Global Summary of the Day - same as below
Climate Reference Network - NA
Local Climatological Data - same as below

Air temp
Hourly global - same as hourly global for precip
GHCN Daily CoCoRaHS - not available
GHCN daily GHCN - same as GHCN daily precip
GHCN Daily WMO - NA
Global Summary of the Day - acquired
Climate Reference Network - NA
Local Climatological Data - available a month at a time

Question: local data hourly observations table has hourly sky conditions, visibility, dry bulb temp, wet bulb temp, dew point temp, rel humidity, 
wind speed, wind direction, wind gusts, station pressure, precip total, altimeter. does anything else have this?
